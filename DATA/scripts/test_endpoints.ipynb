{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "ip = \"http://127.0.0.1:8080\" # can change here with ngrok url\n",
    "requests_urls = {\n",
    "    'upload_data': f\"{ip}/ml/upload-book-vector\",\n",
    "    'update_data': f\"{ip}/ml/update-book-vector\",\n",
    "}\n",
    "\n",
    "data_frame = (pd.read_excel(r'/home/mitul/Projects/NBIC/DATA/nbic_raw_data.xlsx')).fillna('')\n",
    "data_dict = data_frame.loc[0:4].to_dict('records')\n",
    "print(len(data_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_lump in data_dict:\n",
    "    print(requests_urls['upload_data'])\n",
    "    payload = data_lump\n",
    "    response = requests.post(url=requests_urls['upload_data'], json=payload)\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload background check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "import openai\n",
    "import os\n",
    "from langchain.document_loaders import JSONLoader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up os variables\n",
    "os.environ['PINECONE_API_KEY'] = \"\"\n",
    "os.environ['OPENAI_API_KEY'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing pinecone obj\n",
    "pinecone.init(api_key=os.environ['PINECONE_API_KEY'],\n",
    "              environment=\"us-west4-gcp-free\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching relevant results as per query using pinecone CRUD functions\n",
    "\n",
    "query = \"The Powerful Purpose of Introverts: Why the World Needs You to Be You\"\n",
    "\n",
    "#generating embeddings of current query\n",
    "pinecone_index = pinecone.Index('nbic')\n",
    "response = openai.Embedding.create(api_key = os.environ['OPEN_API_KEY'],model=\"text-embedding-ada-002\", input=query)\n",
    "embedding_data = response[\"data\"][0][\"embedding\"]\n",
    "\n",
    "\n",
    "stats = pinecone_index.describe_index_stats()\n",
    "namespace_map = stats['namespaces']\n",
    "namespace_name = list(namespace_map.keys())[0]\n",
    "result = pinecone_index.query(vector= embedding_data , top_k=10000, namespace=namespace_name,include_metadata=True, include_values=True)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching relevant results as per query using Langchain's support functions\n",
    "\n",
    "query = \"The Powerful Purpose of Introverts: Why the World Needs You to Be You\"\n",
    "embeddings = OpenAIEmbeddings()\n",
    "docsearch = Pinecone.from_existing_index('nbic',embeddings)\n",
    "docs = docsearch.similarity_search(query,namespace='nbic',k=6)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# listing function to get all the embeddings\n",
    "def list_all_embeddings(pinecone_index):\n",
    "    stats = pinecone_index.describe_index_stats()\n",
    "    namespace_map = stats['namespaces']\n",
    "    ret = []\n",
    "    for namespace in namespace_map:\n",
    "        vector_count = namespace_map[namespace]['vector_count']\n",
    "        res = pinecone_index.query(vector=[0 for _ in range(1536)], top_k=10000, namespace=namespace, include_metadata=True, include_values=True)\n",
    "        for match in res['matches']:\n",
    "            ret.append(match)\n",
    "    return ret"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "j-ml-blogsgpt",
   "language": "python",
   "name": "j-ml-blogsgpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
